ğŸ® AI Configuration Challenge
Master Prompt Engineering & Multi-Agent Systems

Configure AI agents to generate perfect code â€¢ Maximum Score: 120 points â€¢ Be the AI whisperer! ğŸš€
ğŸ¯ Your Mission: Master AI Configuration to Generate Perfect Code

ğŸ® This is an AI Configuration Game! Instead of writing code yourself, you'll become an AI prompt engineer and system architect. Your goal is to configure AI agents (models, prompts, temperatures, cycles) to automatically generate code that scores the maximum 120 points.

ğŸ† The Challenge:

    ğŸ¤– Configure AI agents - Choose models, craft prompts, set temperatures
    ğŸ”§ Engineer the system - Set cycles, agent specialization, and orchestration
    ğŸ“Š Optimize for scoring - Use the grader feedback to improve your configuration
    ğŸ¯ Achieve perfection - Get your AI to generate 120/120 point solutions consistently

ğŸ”¬ What makes this challenging:

    Different models have different strengths
    Prompt engineering requires precision and creativity
    Temperature affects consistency vs creativity
    Multi-agent coordination needs careful orchestration
    Context length limits force strategic choices

ğŸ› The Coding Challenge Your AI Must Solve

Function to implement: calculate_user_metrics(users, start_date, end_date)

What your AI must figure out:

    Filter users by date range and activity status
    Calculate engagement scores with proper formula
    Handle all edge cases (empty inputs, missing keys, zero division)
    Return top 5 performers sorted correctly
    Provide accurate statistics

ğŸ§  Your AI needs to discover:

    The exact engagement formula: (posts * 2 + comments * 1.5 + likes * 0.1) / days_active
    How to handle days_active = 0 without crashing
    String date comparison logic for filtering
    Proper error handling for missing dictionary keys
    Efficient sorting and top-N selection

ğŸ‘† The Game: Go to 'Configure AI & Generate' to build your AI system, then see the 'Prompt Inspector' to understand exactly what your models receive!
ğŸ¯ Optimization Targets

ğŸ› Critical Bugs (65 pts):

    âŒ Division by zero when days_active = 0
    âŒ Missing dictionary keys
    âŒ Wrong calculation logic
    âŒ Incorrect averaging (all vs active users)

ğŸ”§ Logic Issues (28 pts):

    âŒ Wrong sorting direction
    âŒ No active users in date range
    âŒ Input data mutation

ğŸ¯ Edge Cases (17 pts):

    âŒ Less than 5 users available
    âŒ Invalid date ranges
    âŒ Malformed data handling

âš¡ Performance (10 pts):

    âŒ Inefficient algorithms
    âŒ Unnecessary operations

ğŸ… AI Configuration Strategy

ğŸ¤– Model Selection:

    ğŸ§  llama-3.3-70b: Best overall reasoning
    âš¡ llama3.1-8b: Fast, good for focused tasks
    ğŸ¯ llama-4-scout-17b: Strong at analysis
    ğŸ” qwen-3-32b: Good at edge case detection

ğŸŒ¡ï¸ Temperature Tuning:

    0.0-0.2: Deterministic, consistent output
    0.3-0.5: Balanced creativity/consistency
    0.6-1.0: Creative but potentially inconsistent

ğŸ”„ Multi-Agent Tactics:

    Specialization: Bug finder, edge case handler, optimizer
    Progressive refinement: Multiple cycles for improvement
    Context management: Balance depth vs token limits

ğŸ“ Prompt Engineering:

    Specificity: Mention exact issues to address
    Examples: Reference the scoring criteria
    Structure: Clear instructions and expectations

ğŸ“‹ Test Cases Preview

ğŸ“ What Your AI Will Be Tested Against

ğŸ¯ Success Metrics:

    Grade A (90%+): 108+ points - Your AI is a coding master!
    Grade B (80%+): 96+ points - Excellent AI configuration skills
    Grade C (70%+): 84+ points - Good progress, keep optimizing
    Grade D (60%+): 72+ points - Needs work on edge cases
    Grade F (<60%): <72 points - Major bugs still present

ğŸ† Ultimate Goal: Configure your AI to consistently generate 120/120 point solutions!
